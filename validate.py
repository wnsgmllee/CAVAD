import os 
import re
import numpy as np
import torch
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, average_precision_score
from config import args
from natsort import natsorted

def load_test_list(file_path):
    """ ğŸ“Œ test_list.txtì—ì„œ í…ŒìŠ¤íŠ¸í•  ë¹„ë””ì˜¤ íŒŒì¼ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜´ """
    with open(file_path, "r") as f:
        return sorted([line.strip() for line in f.readlines()], key=lambda x: x.lower())

def find_feature_files(video_name, visual_feature_root, text_feature_root):
    """ ğŸ“Œ íŠ¹ì • ë¹„ë””ì˜¤ì˜ Feature íŒŒì¼ì„ ì°¾ê³  ê²½ë¡œ ë°˜í™˜ """
    
    # âœ… ì²˜ìŒ ë“±ì¥í•˜ëŠ” ìˆ«ì ì•ê¹Œì§€ ê°€ì ¸ì˜¤ê¸°
    match = re.split(r'(\d)', video_name, maxsplit=1)
    category = match[0] if match else video_name  # ìˆ«ì ì• ë¶€ë¶„ì´ ì¹´í…Œê³ ë¦¬ëª…
    if category == "Normal_Videos_":
        category = "Testing_Normal_Videos_Anomaly"

    # âœ… "x264" ì œê±° & "_16frames.npy" ì¶”ê°€
    clean_video_name = video_name.replace("x264", "").strip()
    filename = f"{clean_video_name}16frames.npy"
    
    visual_path = os.path.join(visual_feature_root, category, filename) if visual_feature_root else None
    text_path = os.path.join(text_feature_root, category, filename) if text_feature_root else None

    return visual_path, text_path

def compute_model_scores(model, test_videos, visual_feature_root, text_feature_root, device="cuda"):
    """ ğŸ“Œ ëª¨ë¸ì„ ì´ìš©í•´ Frame-Level ì˜ˆì¸¡ ì ìˆ˜ ê³„ì‚° """
    all_pred_frames = []
    
    for video_name in test_videos:
        visual_path, text_path = find_feature_files(video_name, visual_feature_root, text_feature_root)
        if args.mode == "fusion" and (not visual_path or not text_path):
            print(f"âš ï¸ Warning: Missing features for {video_name}")
            continue
        if args.mode == "visual" and not visual_path:
            print(f"âš ï¸ Warning: Missing visual feature for {video_name}")
            continue
        if args.mode != "fusion" and args.mode != "visual" and not text_path:
            print(f"âš ï¸ Warning: Missing text feature for {video_name}")
            continue

        # âœ… Feature ë¡œë“œ
        visual_feature = torch.tensor(np.load(visual_path), dtype=torch.float32).to(device) if visual_path else None
        text_feature = torch.tensor(np.load(text_path), dtype=torch.float32).to(device) if text_path else None

        # âœ… ëª¨ë¸ ì˜ˆì¸¡
        with torch.no_grad():
            if args.mode == "fusion":
                scores = model(visual_feature, text_feature).cpu().numpy()
            else:
                scores = model(visual_feature if args.mode == "visual" else text_feature).cpu().numpy()

        scores = 1 / (1 + np.exp(-scores))
        frame_scores = np.repeat(scores, 16, axis=0)
        all_pred_frames.append(frame_scores)

    return np.concatenate(all_pred_frames) if all_pred_frames else np.array([])


def validate(model, test_list_path, gt_path, visual_feature_path, text_feature_path):
    """ ğŸ“Œ ëª¨ë¸ ê²€ì¦ """
    model.eval()
    test_videos = np.loadtxt(test_list_path, dtype=str)
    test_videos = natsorted(test_videos)
    # print(f"ğŸ“Œ test_list_path: {test_list_path}")

    pred_scores = compute_model_scores(model, test_videos, visual_feature_path, text_feature_path)
    gt_labels = np.load(gt_path, allow_pickle=False)

    roc_auc = roc_auc_score(gt_labels, pred_scores) if len(pred_scores) > 0 else 0
    ap_score = average_precision_score(gt_labels, pred_scores) 

    # print(f"Validate Results: AUC: {roc_auc:.4f} / AP: {ap_score:.4f}")
    return roc_auc, ap_score


##############################################################################################
def get_video_frame_counts(visual_feature_root, test_videos): # ì •ìƒ
    """
    ğŸ“Œ ê° í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ì˜ í”„ë ˆì„ ê°œìˆ˜ ê³„ì‚°
    - ì •ë ¬ëœ ì˜ìƒëª… ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
    """
    frame_counts = {}
    for video_name in sorted(test_videos, key=lambda x: x.lower()):
        video_name = video_name.replace("x264", "")
        for category in sorted(os.listdir(visual_feature_root)):  # âœ… ì¹´í…Œê³ ë¦¬ë„ ì •ë ¬
            category_path = os.path.join(visual_feature_root, category)
            if not os.path.isdir(category_path):
                continue

            expected_filename = f"{video_name}16frames.npy"
            visual_files = [f for f in os.listdir(category_path) if f == expected_filename]

            if visual_files:
                visual_feature_path = os.path.join(category_path, visual_files[0])
                visual_feature = np.load(visual_feature_path, allow_pickle=False)
                frame_counts[video_name] = visual_feature.shape[0] * 16  # segment ê°œìˆ˜ * 16
                break

    return frame_counts

def plot_anomaly_scores(gt_labels, pred_scores, test_videos, frame_counts, save_path):
    """
    ğŸ“Œ GTì™€ ì˜ˆì¸¡ëœ anomaly scoreë¥¼ ì‹œê°í™”í•˜ì—¬ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    - ì •ë ¬ëœ ì˜ìƒëª… ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
    """
    save_path = os.path.join(save_path, "vis_results")
    os.makedirs(save_path, exist_ok=True)
    start_idx = 0

    # âœ… test_videos ì •ë ¬
    for video_name in sorted(test_videos, key=lambda x: x.lower()):
        video_name = video_name.replace("x264","")
        if video_name not in frame_counts:
            continue
        frame_count = frame_counts[video_name]
        end_idx = start_idx + frame_count

        plt.figure(figsize=(12, 5))
        plt.plot(range(frame_count), gt_labels[start_idx:end_idx], label="Ground Truth", linestyle='dashed', alpha=0.7)
        plt.plot(range(frame_count), pred_scores[start_idx:end_idx], label="Predicted Score", alpha=0.9)
        plt.ylim(0, 1)
        plt.xlabel("Frame")
        plt.ylabel("Anomaly Score")
        plt.title(f"Anomaly Score Plot: {video_name}")
        plt.legend()
        plt.savefig(os.path.join(save_path, f"{video_name}.png"))
        plt.close()

        start_idx = end_idx

def compute_model_scores_frame_level(visual_feature_root, text_feature_root, model, test_videos, device="cuda"):
    """
    ğŸ“Œ ëª¨ë¸ ì˜ˆì¸¡ ì ìˆ˜ ë¡œë“œ ë° Frame-Level ë³€í™˜ (Visual + Text Feature ì‚¬ìš©)
    """
    all_pred_frames = []

    for video_name in test_videos:
        video_name = video_name.replace("x264", "")

        found = False  # ğŸ”¥ íŒŒì¼ì„ ì°¾ì•˜ëŠ”ì§€ ì—¬ë¶€ ì¶”ì 

        for category in sorted(os.listdir(visual_feature_root)):  # âœ… ì¹´í…Œê³ ë¦¬ ì •ë ¬
            visual_category_path = os.path.join(visual_feature_root, category)
            text_category_path = os.path.join(text_feature_root, category)  # âœ… ì¶”ê°€

            if not os.path.isdir(visual_category_path) or not os.path.isdir(text_category_path):
                continue  # í´ë”ê°€ ì•„ë‹ˆë©´ ìŠ¤í‚µ

            expected_filename = f"{video_name}16frames.npy"
            visual_files = [f for f in os.listdir(visual_category_path) if f == expected_filename]
            text_files = [f for f in os.listdir(text_category_path) if f == expected_filename]  # âœ… ì¶”ê°€

            if visual_files and text_files:  # âœ… ë‘ ê°œì˜ featureê°€ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ê²½ìš°
                visual_feature_path = os.path.join(visual_category_path, visual_files[0])
                text_feature_path = os.path.join(text_category_path, text_files[0])

                visual_feature = torch.tensor(np.load(visual_feature_path), dtype=torch.float32).to(device)
                text_feature = torch.tensor(np.load(text_feature_path), dtype=torch.float32).to(device)  # âœ… ì¶”ê°€

                with torch.no_grad():
                    scores = model(visual_feature, text_feature).cpu().numpy()  # âœ… ìˆ˜ì •: text_feature ì¶”ê°€

                scores = 1 / (1 + np.exp(-scores))
                frame_scores = np.repeat(scores, 16, axis=0)
                all_pred_frames.append(frame_scores)

                found = True  # âœ… featureë¥¼ ì°¾ì•˜ìŒ í‘œì‹œ
                break  # âœ… ì •í™•í•œ featureë¥¼ ì°¾ì•˜ìœ¼ë‹ˆ ì¢…ë£Œ

        if not found:
            print(f"âš ï¸ Warning: Feature not found for {video_name}")

    return np.concatenate(all_pred_frames) if all_pred_frames else np.array([])


def validate_and_plot(model):
    """
    ğŸ“Œ Best epochì˜ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ì˜ˆì¸¡ê°’ì„ ê³„ì‚°í•˜ê³ , GTì™€ í•¨ê»˜ ì‹œê°í™”
    """
    result_path = os.path.join("results", args.result_folder)
    os.makedirs(result_path, exist_ok=True)
    model.load_state_dict(torch.load(os.path.join(result_path, "best_model.pth")))
    model.eval()

    test_videos = load_test_list(args.test_list_path)
    frame_counts = get_video_frame_counts(os.path.join(args.visual_root, args.visual_backbone), test_videos)

    gt_labels = np.load(args.gt_feature_path, allow_pickle=False)
    pred_scores = compute_model_scores_frame_level(
        os.path.join(args.visual_root, args.visual_backbone),
        os.path.join(args.text_root, "CAVAD", args.text_backbone),  # âœ… text feature ê²½ë¡œ ì¶”ê°€
        model,
        test_videos
    )

    if len(gt_labels) != len(pred_scores):
        raise ValueError(f"âŒ GTì™€ ì˜ˆì¸¡ê°’ ê¸¸ì´ê°€ ë‹¤ë¦„! GT: {len(gt_labels)}, ì˜ˆì¸¡: {len(pred_scores)}")

    plot_anomaly_scores(gt_labels, pred_scores, test_videos, frame_counts, result_path)


##############################################################################################